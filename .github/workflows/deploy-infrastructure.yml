name: 'Deploy Infrastructure (Terraform) - MANUAL ONLY'

# AUTOMATIC DEPLOYMENT DISABLED
# Uncomment the sections below to re-enable automatic deployment
on:
  # push:
  #   branches:
  #     - main
  #   paths:
  #     - 'terraform/**'
  #     - '.github/workflows/deploy-infrastructure.yml'
  # 
  # pull_request:
  #   branches:
  #     - main
  #   paths:
  #     - 'terraform/**'
  #     - '.github/workflows/deploy-infrastructure.yml'
  
  workflow_dispatch:  # Manual trigger only

env:
  TF_VERSION: '1.7.4'  # Updated to latest stable version
  TERRAFORM_DIR: './terraform'
  STATE_BUCKET: 'bedrock-tfstate-alt-soe-025-0223'
  LOCK_TABLE: 'bedrock-terraform-state-lock'
  CLUSTER_NAME: 'project-bedrock-cluster'
  STATE_KEY: 'bedrock/terraform.tfstate'

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  terraform-plan:
    name: 'Terraform Plan'
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    defaults:
      run:
        working-directory: ${{ env.TERRAFORM_DIR }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Setup Terraform Backend
      run: |
        echo "üîß Setting up Terraform backend..."
        
        # Create S3 bucket for Terraform state if it doesn't exist
        if aws s3api head-bucket --bucket "${{ env.STATE_BUCKET }}" 2>/dev/null; then
          echo "‚úÖ S3 bucket exists: ${{ env.STATE_BUCKET }}"
        else
          echo "üÜï Creating S3 bucket..."
          if [ "${{ secrets.AWS_REGION }}" = "us-east-1" ]; then
            aws s3api create-bucket --bucket "${{ env.STATE_BUCKET }}" --region ${{ secrets.AWS_REGION }}
          else
            aws s3api create-bucket --bucket "${{ env.STATE_BUCKET }}" --region ${{ secrets.AWS_REGION }} \
              --create-bucket-configuration LocationConstraint=${{ secrets.AWS_REGION }}
          fi
        fi
        
        # Enable versioning
        echo "üîí Configuring bucket security..."
        aws s3api put-bucket-versioning --bucket "${{ env.STATE_BUCKET }}" \
          --versioning-configuration Status=Enabled
        
        # Enable encryption (FIXED: Removed corrupted JSON)
        aws s3api put-bucket-encryption --bucket "${{ env.STATE_BUCKET }}" \
          --server-side-encryption-configuration '{
            "Rules": [{
              "ApplyServerSideEncryptionByDefault": {
                "SSEAlgorithm": "AES256"
              },
              "BucketKeyEnabled": true
            }]
          }'
        
        # Block public access
        aws s3api put-public-access-block --bucket "${{ env.STATE_BUCKET }}" \
          --public-access-block-configuration \
          "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
        
        # Create DynamoDB table for state locking if it doesn't exist
        if aws dynamodb describe-table --table-name "${{ env.LOCK_TABLE }}" --region ${{ secrets.AWS_REGION }} 2>/dev/null; then
          echo "‚úÖ DynamoDB table exists: ${{ env.LOCK_TABLE }}"
        else
          echo "üÜï Creating DynamoDB table for state locking..."
          aws dynamodb create-table \
            --table-name "${{ env.LOCK_TABLE }}" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST \
            --region ${{ secrets.AWS_REGION }} \
            --tags Key=Project,Value=Bedrock Key=ManagedBy,Value=Terraform
          
          echo "‚è≥ Waiting for table to be active..."
          aws dynamodb wait table-exists --table-name "${{ env.LOCK_TABLE }}" --region ${{ secrets.AWS_REGION }}
          echo "‚úÖ DynamoDB table ready"
        fi
        
        echo "‚úÖ Backend setup complete!"
    
    - name: Terraform Format Check
      run: |
        echo "üé® Checking Terraform formatting..."
        terraform fmt -check -recursive
        echo "‚úÖ Terraform formatting is correct"
    
    - name: Terraform Init
      run: |
        echo "üöÄ Initializing Terraform..."
        terraform init
        echo "‚úÖ Terraform initialized successfully"
    
    - name: Terraform Validate
      run: |
        echo "üîç Validating Terraform configuration..."
        terraform validate
        echo "‚úÖ Terraform configuration is valid"
    
    - name: Security Scan (tfsec)
      run: |
        echo "üõ°Ô∏è Running security scan..."
        # Install tfsec if not available
        curl -s https://raw.githubusercontent.com/aquasecurity/tfsec/master/scripts/install_linux.sh | bash
        ./tfsec . --format lovely || echo "‚ö†Ô∏è Security scan completed with warnings"
      continue-on-error: true
    
    - name: Terraform Plan
      id: plan
      run: |
        echo "üìã Creating Terraform execution plan..."
        terraform plan -no-color -out=tfplan
        terraform show -no-color tfplan > plan.txt
        echo "‚úÖ Plan created successfully"
    
    - name: Comment Plan on PR
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request'
      with:
        script: |
          const fs = require('fs');
          const plan = fs.readFileSync('terraform/plan.txt', 'utf8');
          const maxGitHubBodyCharacters = 65536;
          
          function chunkSubstr(str, size) {
            const numChunks = Math.ceil(str.length / size)
            const chunks = new Array(numChunks)
            for (let i = 0, o = 0; i < numChunks; ++i, o += size) {
              chunks[i] = str.substr(o, size)
            }
            return chunks
          }
          
          // Split the Terraform plan into chunks if it's too big
          var plans = chunkSubstr(plan, maxGitHubBodyCharacters); 
          for (let i = 0; i < plans.length; i++) {
            const output = `### Terraform Plan Output (Part ${i + 1} of ${plans.length})
            
            \`\`\`terraform
            ${plans[i]}
            \`\`\`
            
            **Branch:** ${{ github.head_ref }}
            **Triggered by:** @${{ github.actor }}
            
            *Review the plan carefully before merging to main.*
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            });
          }

  terraform-apply:
    name: 'Terraform Apply'
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    
    defaults:
      run:
        working-directory: ${{ env.TERRAFORM_DIR }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Setup Terraform Backend
      run: |
        echo "üîß Setting up Terraform backend (S3 + DynamoDB)..."
        
        # Create S3 bucket for Terraform state if it doesn't exist
        if aws s3api head-bucket --bucket "${{ env.STATE_BUCKET }}" 2>/dev/null; then
          echo "‚úÖ S3 bucket exists: ${{ env.STATE_BUCKET }}"
        else
          echo "üÜï Creating S3 bucket: ${{ env.STATE_BUCKET }}"
          if [ "${{ secrets.AWS_REGION }}" = "us-east-1" ]; then
            aws s3api create-bucket --bucket "${{ env.STATE_BUCKET }}" --region ${{ secrets.AWS_REGION }}
          else
            aws s3api create-bucket --bucket "${{ env.STATE_BUCKET }}" --region ${{ secrets.AWS_REGION }} \
              --create-bucket-configuration LocationConstraint=${{ secrets.AWS_REGION }}
          fi
        fi
        
        # Configure bucket security (only if bucket was just created or needs update)
        echo "üîí Configuring bucket security..."
        
        # Enable versioning
        aws s3api put-bucket-versioning --bucket "${{ env.STATE_BUCKET }}" \
          --versioning-configuration Status=Enabled
        
        # Enable encryption
        aws s3api put-bucket-encryption --bucket "${{ env.STATE_BUCKET }}" \
          --server-side-encryption-configuration '{
            "Rules": [{
              "ApplyServerSideEncryptionByDefault": {
                "SSEAlgorithm": "AES256"
              },
              "BucketKeyEnabled": true
            }]
          }'
        
        # Block public access
        aws s3api put-public-access-block --bucket "${{ env.STATE_BUCKET }}" \
          --public-access-block-configuration \
          "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
        
        # Create DynamoDB table for state locking if it doesn't exist
        if aws dynamodb describe-table --table-name "${{ env.LOCK_TABLE }}" --region ${{ secrets.AWS_REGION }} 2>/dev/null; then
          echo "‚úÖ DynamoDB table exists: ${{ env.LOCK_TABLE }}"
        else
          echo "üÜï Creating DynamoDB table for state locking..."
          aws dynamodb create-table \
            --table-name "${{ env.LOCK_TABLE }}" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST \
            --region ${{ secrets.AWS_REGION }} \
            --tags Key=Project,Value=Bedrock Key=ManagedBy,Value=Terraform
          
          echo "‚è≥ Waiting for DynamoDB table to be active..."
          aws dynamodb wait table-exists --table-name "${{ env.LOCK_TABLE }}" --region ${{ secrets.AWS_REGION }}
          echo "‚úÖ DynamoDB table ready"
        fi
        
        echo "‚úÖ Backend setup complete!"

    - name: Terraform Init
      run: |
        echo "üöÄ Initializing Terraform..."
        terraform init
        echo "‚úÖ Terraform initialized successfully"

    - name: Validate Backend Configuration
      run: |
        echo "üîç Validating backend configuration..."
        
        # Check if backend connection is working
        if terraform state list > /dev/null 2>&1; then
          echo "‚úÖ Backend connection successful"
          
          # Show backend configuration info
          echo "Backend Details:"
          echo "  Bucket: ${{ env.STATE_BUCKET }}"
          echo "  Key: ${{ env.STATE_KEY }}"
          echo "  Lock Table: ${{ env.LOCK_TABLE }}"
          echo "  Region: ${{ secrets.AWS_REGION }}"
        else
          echo "‚ùå Backend connection failed"
          echo "This might be a fresh deployment with no state yet"
        fi

    - name: Terraform Validate
      run: |
        echo "üîç Validating Terraform configuration..."
        terraform validate
        echo "‚úÖ Configuration validated"

    - name: Create State Backup
      run: |
        echo "üíæ Creating backup of current Terraform state..."
        BACKUP_FILE="state-backup-$(date +%Y%m%d-%H%M%S).json"
        
        if aws s3 cp s3://${{ env.STATE_BUCKET }}/${{ env.STATE_KEY }} "./$BACKUP_FILE" 2>/dev/null; then
          echo "‚úÖ State backup created: $BACKUP_FILE"
          # Upload backup to a separate location
          aws s3 cp "./$BACKUP_FILE" s3://${{ env.STATE_BUCKET }}/backups/$BACKUP_FILE
          echo "‚úÖ Backup stored in S3: s3://${{ env.STATE_BUCKET }}/backups/$BACKUP_FILE"
        else
          echo "üÜï No existing state file - fresh deployment"
        fi
    - name: Clean Problematic State Resources
      run: |
        echo "üßΩ Checking for problematic resources in state..."
        
        if [ ! -f "state-backup-"*".json" ]; then
          echo "üÜï No existing state to clean - fresh deployment"
          exit 0
        fi
        
        STATE_FILE=$(ls state-backup-*.json 2>/dev/null | head -1)
        
        # Count problematic resources
        PROBLEM_COUNT=$(cat "$STATE_FILE" | jq '[.resources[] | select(
          .type == "kubernetes_cluster_role" or 
          .type == "kubernetes_cluster_role_binding" or 
          .type == "aws_eks_pod_identity_association"
        )] | length' 2>/dev/null || echo "0")
        
        if [ "$PROBLEM_COUNT" -gt "0" ]; then
          echo "‚ö†Ô∏è Found $PROBLEM_COUNT problematic resources in state"
          
          # Show what will be removed
          cat "$STATE_FILE" | jq -r '.resources[] | select(
            .type == "kubernetes_cluster_role" or 
            .type == "kubernetes_cluster_role_binding" or 
            .type == "aws_eks_pod_identity_association"
          ) | "  - \(.type).\(.name)"' || true
          
          echo "üßΩ Cleaning state..."
          
          # Remove problematic resources
          cat "$STATE_FILE" | jq 'del(.resources[] | select(
            .type == "kubernetes_cluster_role" or 
            .type == "kubernetes_cluster_role_binding" or 
            .type == "aws_eks_pod_identity_association"
          ))' > ./state-cleaned.json
          
          # Verify cleaning worked
          REMAINING=$(cat ./state-cleaned.json | jq '[.resources[] | select(
            .type == "kubernetes_cluster_role" or 
            .type == "kubernetes_cluster_role_binding" or 
            .type == "aws_eks_pod_identity_association"
          )] | length' 2>/dev/null || echo "999")
          
          if [ "$REMAINING" -eq "0" ]; then
            # Upload cleaned state back to S3
            aws s3 cp ./state-cleaned.json s3://${{ env.STATE_BUCKET }}/${{ env.STATE_KEY }}
            echo "‚úÖ Successfully removed $PROBLEM_COUNT problematic resources from state"
          else
            echo "‚ùå ERROR: Failed to clean state properly (remaining: $REMAINING)"
            exit 1
          fi
        else
          echo "‚úÖ No problematic resources found - state is clean"
        fi
    
    - name: Terraform Apply
      id: apply
      run: |
        echo "üöÄ Deploying infrastructure..."
        echo "Cluster: ${{ env.CLUSTER_NAME }}"
        echo "Region: ${{ secrets.AWS_REGION }}"
        echo "State: s3://${{ env.STATE_BUCKET }}/${{ env.STATE_KEY }}"
        echo ""
        
        # Run terraform apply with detailed logging
        if terraform apply -auto-approve -no-color; then
          echo "‚úÖ Infrastructure deployment completed successfully!"
          echo "apply_success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Infrastructure deployment failed!"
          echo "apply_success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
    
    - name: Verify EKS Cluster
      if: steps.apply.outputs.apply_success == 'true'
      run: |
        echo "üîç Verifying EKS cluster deployment..."
        
        # Wait for cluster to be active (max 10 minutes)
        echo "Waiting for cluster to be ACTIVE..."
        for i in {1..60}; do
          STATUS=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --query 'cluster.status' --output text 2>/dev/null || echo "NOT_FOUND")
          
          case $STATUS in
            "ACTIVE")
              echo "‚úÖ EKS cluster is ACTIVE and ready!"
              break
              ;;
            "CREATING")
              echo "‚è≥ Cluster is still creating... ($i/60)"
              ;;
            "NOT_FOUND")
              echo "‚ùå Cluster not found after apply - this shouldn't happen"
              exit 1
              ;;
            *)
              echo "‚ö†Ô∏è Cluster status: $STATUS ($i/60)"
              ;;
          esac
          
          if [ $i -eq 60 ]; then
            echo "‚ö†Ô∏è Timeout waiting for cluster to be ACTIVE. Current status: $STATUS"
            echo "Cluster may still be initializing. Check AWS Console."
          fi
          
          sleep 10
        done
    
    - name: Install EBS CSI Driver Addon
      if: success()
      run: |
        echo "üîå Installing EBS CSI Driver addon..."
        
        # Check if addon already exists
        if aws eks describe-addon \
          --cluster-name ${{ env.CLUSTER_NAME }} \
          --addon-name aws-ebs-csi-driver \
          --region ${{ secrets.AWS_REGION }} 2>/dev/null; then
          
          echo "‚ö†Ô∏è EBS CSI Driver addon already exists"
          
          # Check if it needs updating
          CURRENT_VERSION=$(aws eks describe-addon \
            --cluster-name ${{ env.CLUSTER_NAME }} \
            --addon-name aws-ebs-csi-driver \
            --region ${{ secrets.AWS_REGION }} \
            --query 'addon.addonVersion' --output text)
          
          echo "Current version: $CURRENT_VERSION"
          echo "‚úÖ EBS CSI Driver addon is already installed"
        else
          echo "üÜï Creating EBS CSI Driver addon..."
          
          # Get the latest supported version
          LATEST_VERSION=$(aws eks describe-addon-versions \
            --addon-name aws-ebs-csi-driver \
            --kubernetes-version $(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --query 'cluster.version' --output text) \
            --region ${{ secrets.AWS_REGION }} \
            --query 'addons[0].addonVersions[0].addonVersion' --output text 2>/dev/null || echo "")
          
          ADDON_ARGS="--cluster-name ${{ env.CLUSTER_NAME }} --addon-name aws-ebs-csi-driver --region ${{ secrets.AWS_REGION }} --resolve-conflicts OVERWRITE"
          
          if [ -n "$LATEST_VERSION" ]; then
            ADDON_ARGS="$ADDON_ARGS --addon-version $LATEST_VERSION"
            echo "Installing version: $LATEST_VERSION"
          fi
          
          if aws eks create-addon $ADDON_ARGS; then
            echo "‚è≥ Waiting for addon to be active (may take 5-15 minutes)..."
            
            # Wait for addon with timeout
            timeout 900 aws eks wait addon-active \
              --cluster-name ${{ env.CLUSTER_NAME }} \
              --addon-name aws-ebs-csi-driver \
              --region ${{ secrets.AWS_REGION }} || {
              echo "‚ö†Ô∏è Addon creation timed out but may still be installing"
              echo "Check addon status: aws eks describe-addon --cluster-name ${{ env.CLUSTER_NAME }} --addon-name aws-ebs-csi-driver"
            }
            
            echo "‚úÖ EBS CSI Driver addon installation completed"
          else
            echo "‚ùå Failed to create EBS CSI Driver addon"
            exit 1
          fi
        fi
    
    - name: Deployment Summary
      if: always()
      run: |
        echo ""
        echo "====================================================="
        echo "üéÜ INFRASTRUCTURE DEPLOYMENT SUMMARY"
        echo "====================================================="
        echo "Date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        echo "Triggered by: @${{ github.actor }}"
        echo "Branch: ${{ github.ref_name }}"
        echo "Cluster: ${{ env.CLUSTER_NAME }}"
        echo "Region: ${{ secrets.AWS_REGION }}"
        echo "State: s3://${{ env.STATE_BUCKET }}/${{ env.STATE_KEY }}"
        echo ""
        
        # Show terraform outputs if apply was successful
        if [ "${{ steps.apply.outputs.apply_success }}" = "true" ]; then
          echo "üìà Terraform Outputs:"
          echo "-----------------------------------------------------"
          terraform output -no-color || echo "No outputs available"
          echo "-----------------------------------------------------"
          echo ""
          
          # Show cluster info
          echo "üîç EKS Cluster Information:"
          CLUSTER_STATUS=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --query 'cluster.status' --output text 2>/dev/null || echo "UNKNOWN")
          CLUSTER_VERSION=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --query 'cluster.version' --output text 2>/dev/null || echo "UNKNOWN")
          CLUSTER_ENDPOINT=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --query 'cluster.endpoint' --output text 2>/dev/null || echo "UNKNOWN")
          
          echo "  Status: $CLUSTER_STATUS"
          echo "  Version: $CLUSTER_VERSION"
          echo "  Endpoint: $CLUSTER_ENDPOINT"
          echo ""
          
          # Check addon status
          echo "üîå EKS Add-ons:"
          aws eks list-addons --cluster-name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --output table 2>/dev/null || echo "  Could not retrieve add-on information"
          echo ""
          
          echo "‚úÖ DEPLOYMENT SUCCESSFUL!"
          echo ""
          echo "Next steps:"
          echo "1. Verify EKS cluster status in AWS Console"
          echo "2. Wait for EBS CSI Driver add-on to be fully active (~5 minutes)"
          echo "3. Deploy applications using the 'Deploy Application' workflow"
          echo "4. Configure kubectl: aws eks update-kubeconfig --name ${{ env.CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }}"
        else
          echo "‚ùå DEPLOYMENT FAILED!"
          echo "Please check the job logs above for error details."
        fi
        
        echo "====================================================="